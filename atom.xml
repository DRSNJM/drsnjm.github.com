<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Dinosaur Riding Scrum Ninja Jedi Masters]]></title>
  <link href="http://DRSNJM.github.com/atom.xml" rel="self"/>
  <link href="http://DRSNJM.github.com/"/>
  <updated>2012-12-12T21:10:21-05:00</updated>
  <id>http://DRSNJM.github.com/</id>
  <author>
    <name><![CDATA[Ryan McGowan, Alex Burkhart, David Albert, Chris Powers]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Similarity Engine - Alternate Methods]]></title>
    <link href="http://DRSNJM.github.com/blog/2012/12/12/similarity-engine-alternate-methods/"/>
    <updated>2012-12-12T19:15:00-05:00</updated>
    <id>http://DRSNJM.github.com/blog/2012/12/12/similarity-engine-alternate-methods</id>
    <content type="html"><![CDATA[<h2>Neural Network Approach</h2>

<p>After training the neural network on approximately 200 training samples, it was evident that the network did not necessarily generalize to games outside of the scope of the ones rated by experts in the training set. Further input will be necessary to continue to complete the model; this will hopefully be completed in the coming weeks as Alex makes more vists to CABS meetings. Once a better picture of the training data develops, the network should hypothetically generalize better to the regions of the input space that do not perform well at this point in time (for instance, war games.) This portion of the project will continue to be a work in progress. In the mean time, as seen in our progress reports, I have also set up an alternate method to provide users with a very literal correlation of similarity between games.</p>

<h2>Simple Statistical Approach</h2>

<p>In order to provide results that were more relevant in the immediate context of publicizing our project, I introduced an alternate method to the neural network approach that backtracks to some of the work that I had done earlier in the project. Rather than train an network with the training data, the stats method performs component analysis to return a 10 dimensional vector for each game. The confidence level for each game relative to the other games is then calculated merely from the euclidean distance between the two vectors.</p>

<h3>Drawbacks</h3>

<p>While this method provides games that are numerically similar to each other, often returning different versions of the same title in the search results, it fails to meet our initial goal of providing users with recommendations based on the more esoteric relationships with games. While two games, by their attributes, may be incredibly similar, they may be a poor recommendation, particularly if the user is looking for variety and new options in the games that they are playing. It is for these reasons that, while we are leaving this method as an option, we would much prefer the neural net approach to be used and to be successful in providing users with a diverse listing of similar games.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tag Administration]]></title>
    <link href="http://DRSNJM.github.com/blog/2012/12/12/tag-administration/"/>
    <updated>2012-12-12T17:39:00-05:00</updated>
    <id>http://DRSNJM.github.com/blog/2012/12/12/tag-administration</id>
    <content type="html"><![CDATA[<h2>Purpose</h2>

<p>In all the Board Game Geek data, there are a lot of different Mechanics and
Categories. Within the system they are treated identically, collectively
called Tags. Each Tag has a name along with a detailed description.</p>

<p>We wanted to be able to quickly modify the metadata related to the Tags quickly
and easily. We already had a webserver setup, so a simple web interface seemed
a natural way to accomplish this.</p>

<h2>Features</h2>

<p>With the Tag Administration page, we were able to edit the titles and
descriptions of each tag as we see fit. We pulled all the descriptions in from
Board Game Geek with a script automatically and were able to quickly edit them
here.</p>

<p>We also wanted to be able to modify the weight for each Tag within the query
scoring system. I added a &#8220;Postive Influence&#8221; and &#8220;Negative Influence&#8221; field to
each Tag. By modifying the Postive Influence, an administrator is able to
change the maximum score assigned to an attribute by the query engine.
Similarly, the Negative Influence adjusts the maximum penalty when an attribute
is marked thumbs down by the user.</p>

<p>Lastly, we had plans to break up the giant wall of tri-state checkboxes on the
query page by grouping related Tags. A common example of this was to group all
&#8220;Theme&#8221; tags together. The administration page gave us a simple way to change
the grouping.</p>

<p><img src="http://DRSNJM.github.com/images/tag_administration.png" alt="Preview" /></p>

<p>You can see the final version of the Tag Administration Page
<a href="http://board-ultimatum.herokuapp.com/tags">here</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Expert Interface]]></title>
    <link href="http://DRSNJM.github.com/blog/2012/12/12/expert-interface/"/>
    <updated>2012-12-12T15:29:00-05:00</updated>
    <id>http://DRSNJM.github.com/blog/2012/12/12/expert-interface</id>
    <content type="html"><![CDATA[<h2>Purpose</h2>

<p>Data for the similarity engine (neural network) did not come out of thin air. It
needed to be collected from our experts. The purpose of expert authentication
and the expert interface is to easily allow our experts to contribute to the
training of the neural network. The end goal is for an expert to rate each game
as similar to another one. With 1,000 games there ate 500,000 pairs (1,000
choose 2). Getting 500,000 ratings at our scale is difficult thus the neural
network is needed to expand on the ratings we have.</p>

<h2>Issues &amp; Design</h2>

<p>Our initial design was very simple. A random pair of games is selected. If the
expert is familiar with both games, they rate how similar they are. Otherwise,
he or she skips that pair. Unfortunately, most experts are not familiar with a
significant proportion of the games in our database. That means, under normal
conditions the expert would be skipping a lot.</p>

<p>To address this the interface was turned into a wizard with the following steps:</p>

<ol>
<li>Game Selection &#8211; 12 random games are selected from the database. The expert
selectis which one they are familiar.</li>
<li>Pair Rating &#8211; For all pair combinations of games selected on page 1 obtain
a rating from the expert.</li>
</ol>


<p>An expert is far more likely to be familiar with 2 or more games out of a
randomly selected twelve. Thus, less skipping is involved.</p>

<h2>Features</h2>

<ul>
<li>Do not display games the expert has not seen before.</li>
<li>Limit the number of combinations shown.</li>
<li>Do not show combinations the expert has already rated.</li>
</ul>


<h4><a href="https://github.com/DRSNJM/board-ultimatum/blob/master/src/board_ultimatum/views/expert.clj">Source Code</a></h4>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Development Setup]]></title>
    <link href="http://DRSNJM.github.com/blog/2012/12/12/development-setup/"/>
    <updated>2012-12-12T14:53:00-05:00</updated>
    <id>http://DRSNJM.github.com/blog/2012/12/12/development-setup</id>
    <content type="html"><![CDATA[<p>Setting up this board ultimatum for development is not a complicated task, but
it has several dependencies. Most notably, you will need to install a
project and dependency management tool for Clojure called leiningen.
Installation and usage instructions for leiningen can be found on <a href="https://github.com/technomancy/leiningen">its github
page</a>.</p>

<p>You can get a <a href="https://github.com/DRSNJM/board-ultimatum/archive/master.zip">zip of our current source
code</a> but we
suggest using <a href="http://git-scm.com/">git</a> which can be downloaded
<a href="http://git-scm.com/downloads">here</a>.</p>

<p>Once you have leiningen setup the <a href="https://github.com/DRSNJM/board-ultimatum">instructions on our github
repository</a> should suffice. Further
dependencies exist if you want to modify or use styles. <a href="https://github.com/DRSNJM/board-ultimatum#modifying-styles">Instructions for doing
this</a> are also
available on the projects README.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Final System Design]]></title>
    <link href="http://DRSNJM.github.com/blog/2012/12/11/final-system-design/"/>
    <updated>2012-12-11T19:44:00-05:00</updated>
    <id>http://DRSNJM.github.com/blog/2012/12/11/final-system-design</id>
    <content type="html"><![CDATA[<p>The overall design of the system is now solidified. Here&#8217;s a quick look at our design:</p>

<p><img src="http://DRSNJM.github.com/images/diagrams/system-design.png" alt="System Design" /></p>

<p>It may be a bit simplified, but it captures all of the core elements of the system.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Final Presentation]]></title>
    <link href="http://DRSNJM.github.com/blog/2012/12/10/final-presentation/"/>
    <updated>2012-12-10T20:39:00-05:00</updated>
    <id>http://DRSNJM.github.com/blog/2012/12/10/final-presentation</id>
    <content type="html"><![CDATA[<p>We&#8217;ll be presenting our capstone project at
<a href="http://www.ceti.cse.ohio-state.edu/">CETI</a> day. You can <a href="https://docs.google.com/presentation/pub?id=12pCKA2sX9XIYasMh3BmRr6pTsjaWTVhSagITDBASn5M&amp;start=false&amp;loop=false&amp;delayms=3000">view the poster we
made here</a>.</p>

<p>The relative breakdown of work on the poster and presentation was as follows:</p>

<h2>Worklog</h2>

<h3>Poster</h3>

<ul>
<li>Template styling and modification &#8212; <em>David</em></li>
<li>Initial outline content &#8212; <em>Ryan</em></li>
<li>Created and arranged design flowchart &#8212; <em>Chris</em></li>
<li>Added some parts to the design text &#8212; <em>Chris</em></li>
</ul>


<h3>board-ultimatum</h3>

<ul>
<li>Create simple statistical method for determining similarity of games. &#8212;
<em>David</em></li>
<li><p>Allow the user to specify similarity engine provider. See the
<a href="https://github.com/DRSNJM/board-ultimatum/pull/12">pull-request</a> &#8212;
<em>Ryan</em></p>

<p>Providers:</p>

<ul>
<li>Neural Network</li>
<li>Simple Stats</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Timebox 6]]></title>
    <link href="http://DRSNJM.github.com/blog/2012/11/26/timebox-6/"/>
    <updated>2012-11-26T21:59:00-05:00</updated>
    <id>http://DRSNJM.github.com/blog/2012/11/26/timebox-6</id>
    <content type="html"><![CDATA[<h2>Worklog</h2>

<h3>Chris Powers</h3>

<ul>
<li></li>
</ul>


<h3>Alex Burkhart</h3>

<ul>
<li></li>
</ul>


<h3>Ryan McGowan</h3>

<ul>
<li></li>
</ul>


<h3>David Albert</h3>

<ul>
<li>Created icons for recommendation GUI</li>
<li>Added cross validation to the Neural Net system</li>
<li>Refined similar search results UI</li>
</ul>


<h2>Commit History</h2>

<p>For more information on who has done what see <a href="https://github.com/DRSNJM/board-ultimatum/commits/master">our commit
history</a> on our github
project.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Meeting 15]]></title>
    <link href="http://DRSNJM.github.com/blog/2012/11/18/meeting-15/"/>
    <updated>2012-11-18T16:55:00-05:00</updated>
    <id>http://DRSNJM.github.com/blog/2012/11/18/meeting-15</id>
    <content type="html"><![CDATA[<h2>Goals</h2>

<ul>
<li>Finish up attribute scoring weights</li>
</ul>


<h2>Discussion</h2>

<p>Alex was almost finished adding all weights for current attributes. Alex wanted
to add a separate page for setting mechanics and category weights.</p>

<p>Alex requested that Chris add scoring and explanations on the weight attribute.
Ideally, the all games would be scored on their weight, so a closeness fit
function needs to be used to score the real valued differences between weights.</p>

<h2>Results</h2>

<p>Chris successfully added a scoring function as hoped for weights.</p>

<p>Alex added a page where users can modify the tag weightings and modify the
explanation for any tag. The negative and positive tag weightings can be
independently modified.</p>

<h2>Outgoing Responsibilities</h2>

<ul>
<li>Add full explanations to different weight scores &#8212; <em>Chris</em></li>
<li>Populate tag weights and explanations &#8212; <em>Alex</em></li>
</ul>


<h2>Attendance</h2>

<ul>
<li>Alex Burkhart</li>
<li>Chris Powers (scribe)</li>
</ul>


<h2>Location</h2>

<p>Campfirenow Chat</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Timebox 5]]></title>
    <link href="http://DRSNJM.github.com/blog/2012/11/12/timebox-5/"/>
    <updated>2012-11-12T17:22:00-05:00</updated>
    <id>http://DRSNJM.github.com/blog/2012/11/12/timebox-5</id>
    <content type="html"><![CDATA[<h2>Worklog</h2>

<h3>Chris Powers</h3>

<ul>
<li>Created the <a href="https://github.com/DRSNJM/board-ultimatum/blob/attr-search/src/board_ultimatum/attr_engine.clj">attribute scoring engine</a></li>
<li>Implemented <a href="https://github.com/DRSNJM/board-ultimatum/blob/attr-search/src/board_ultimatum/engine/model.clj">filtering on the number of players</a></li>
<li>Added results page sorting by score.</li>
<li>Hooked up front-end with filtering and scoring components to ensure queries now work (takes user input, pulls data, filters, scores, presents, in that order)</li>
</ul>


<h3>Alex Burkhart</h3>

<ul>
<li></li>
</ul>


<h3>Ryan McGowan</h3>

<ul>
<li>Completed expert functionality. (<a href="https://github.com/DRSNJM/board-ultimatum/commits/expert-auth">Commits</a>)
<br /><strong>Highlights:</strong>

<ul>
<li>Designed and implemented routes and markup for expert-select and
expert-compare interfaces</li>
<li>Designed and implemented basic insecure expert authentication.</li>
<li>Some minor style changes/improvements.</li>
<li>Rewrite of <a href="https://github.com/DRSNJM/board-ultimatum/blob/cf44804eb7531caac6e89463d9a2c140c54abfcf/resources/public/js/expert.js"><code>expert.js</code></a></li>
<li>Created the following helper namespaces (engine.model.expert,
engine.model.relationship, form-validators, session, flash). <a href="https://github.com/DRSNJM/board-ultimatum/tree/expert-auth/src/board_ultimatum">Explore
here</a>.</li>
</ul>
</li>
</ul>


<h3>David Albert</h3>

<ul>
<li>Create auto-completing search UI for finding similar games</li>
<li>Connect UI to database containing results from neural network</li>
</ul>


<h2>Commit History</h2>

<p>For more information on who has done what see <a href="https://github.com/DRSNJM/board-ultimatum/commits/master">our commit
history</a> on our github
project.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Meeting 14]]></title>
    <link href="http://DRSNJM.github.com/blog/2012/11/12/meeting-14/"/>
    <updated>2012-11-12T13:00:00-05:00</updated>
    <id>http://DRSNJM.github.com/blog/2012/11/12/meeting-14</id>
    <content type="html"><![CDATA[<h2>Goals</h2>

<ul>
<li>Determine how to include simple stats and neural network results.</li>
</ul>


<h2>Discussion</h2>

<p>Despite not having good results from the neural network thus far, replacing our
network output data with the simple statistics data was undesirable. We are
somewhat hopeful that the neural network will perform, but since the simple
statistics shows good results we want the user to use it if they want.</p>

<h2>Results</h2>

<p>On the results page and the similar search page there are toggle buttons that
allow the similarity provider to be selected.</p>

<h2>Outgoing Responsibilities</h2>

<ul>
<li>Create UI for provider selection &#8212; <em>Ryan</em></li>
<li>Train and push output data for both collections &#8212; <em>David</em></li>
</ul>


<h2>Attendance</h2>

<ul>
<li>David Albert</li>
<li>Ryan McGowan (scribe)</li>
</ul>


<h2>Location</h2>

<p>Google Chat</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Timebox 4]]></title>
    <link href="http://DRSNJM.github.com/blog/2012/11/02/timebox-4/"/>
    <updated>2012-11-02T12:03:00-04:00</updated>
    <id>http://DRSNJM.github.com/blog/2012/11/02/timebox-4</id>
    <content type="html"><![CDATA[<h2>Worklog</h2>

<h3>Chris Powers</h3>

<ul>
<li>Created the <a href="https://github.com/DRSNJM/board-ultimatum/blob/attr-search/src/board_ultimatum/attr_engine.clj">attribute scoring engine</a></li>
<li>Implemented <a href="https://github.com/DRSNJM/board-ultimatum/blob/attr-search/src/board_ultimatum/engine/model.clj">filtering on the number of players</a></li>
<li>Added results page sorting by score.</li>
<li>Hooked up front-end with filtering and scoring components to ensure queries now work (takes user input, pulls data, filters, scores, presents, in that order)</li>
</ul>


<h3>Alex Burkhart</h3>

<ul>
<li></li>
</ul>


<h3>Ryan McGowan</h3>

<ul>
<li>Created expert interface. (<a href="https://github.com/DRSNJM/board-ultimatum/commits/expert-auth">Commits</a>)
<br /><strong>Highlights:</strong>

<ul>
<li>Designed and implemented routes and markup for expert-select and
expert-compare interfaces</li>
<li>Designed and implemented basic insecure expert authentication.</li>
<li>Some minor style changes/improvements.</li>
<li>Rewrite of <a href="https://github.com/DRSNJM/board-ultimatum/blob/cf44804eb7531caac6e89463d9a2c140c54abfcf/resources/public/js/expert.js"><code>expert.js</code></a></li>
<li>Created the following helper namespaces (engine.model.expert,
engine.model.relationship, form-validators, session, flash). <a href="https://github.com/DRSNJM/board-ultimatum/tree/expert-auth/src/board_ultimatum">Explore
here</a>.</li>
</ul>
</li>
</ul>


<h3>David Albert</h3>

<ul>
<li>Data Processing and Neural Net Setup

<ul>
<li>See blog post <a href="http://DRSNJM.github.com/blog/2012/10/31/data-analysis-and-neural-nets/">here</a></li>
<li><a href="https://github.com/DRSNJM/board-ultimatum/blob/nnet/src/board_ultimatum/engine/vector_convert.clj">Data Converstion Script</a></li>
<li><a href="https://github.com/DRSNJM/board-ultimatum/blob/nnet/src/board_ultimatum/engine/neural.clj">Neural Net Script</a></li>
</ul>
</li>
</ul>


<h2>Commit History</h2>

<p>For more information on who has done what see <a href="https://github.com/DRSNJM/board-ultimatum/commits/master">our commit
history</a> on our github
project.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Data Analysis and Neural Nets]]></title>
    <link href="http://DRSNJM.github.com/blog/2012/10/31/data-analysis-and-neural-nets/"/>
    <updated>2012-10-31T18:17:00-04:00</updated>
    <id>http://DRSNJM.github.com/blog/2012/10/31/data-analysis-and-neural-nets</id>
    <content type="html"><![CDATA[<h2>Data Conversion and Analysis</h2>

<p>The first task that I took on during this timebox was converting the data from the board game database into numerical vectors representing each game. The source code for this script can be found <a href="https://github.com/DRSNJM/board-ultimatum/blob/nnet/src/board_ultimatum/engine/vector-convert.clj">here</a>. There are many categories and mechanics included in this vector - its value is 1.0 if the game contains that tag and 0.0 if it does not.</p>

<p>As you can tell by examining the code, the resulting vector has 100+ dimensions. For the sake of performance, I decided that this raw input was impractical for a neural net application. To solve this problem, I turned to PCA (Principal Component Analysis). PCA uses orthagonal transforms to maximize the variability of the data. By projecting my set of 1000 100+ dimensional vectors onto the first 10 principal components, I was able to reduce the dimensionality of the vectors down to ten components. The following is a graph of the data on the first two principal components.</p>

<p><img src="http://i.imgur.com/XEnty.png" alt="PC Analysis" /></p>

<p>It is worthwhile to note that the outliers in the bottom right are party games that can accomodate 50+ people and are fairly unique in that regard.</p>

<p>Once the data is converted, it is stored in the Mongo database.</p>

<p>The library I used to perform this analysis is <a href="http://incanter.org/">Incanter</a> which contains much of the functionality found in R, if you are familiar with stats packages.</p>

<h2>Neural Net and Engine output</h2>

<p>The next step was to run the data through the neural net. Since the expert interface is not accessible to public users at this point, an untrained network is used. The network I used is arbitrary at this point as far as hidden layers and propogation algorithms are concerned, since there is no training data. I ran each combination of games through the network with the input as the following: [GameA Game B]. The results were then stored in another Mongo collection.</p>

<p>One problem that I encountered was the amount of storage that the output takes. This problem was mitigated by only storing the 50 games with the best score for each game, reducing the size by a factor of 20. All 1000 values would be calculated, then trimmed down. This would ensure that the database would never have more than ~50000 records, versus 1000000.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Designing the Scoring Engine]]></title>
    <link href="http://DRSNJM.github.com/blog/2012/10/30/designing-the-scoring-engine/"/>
    <updated>2012-10-30T18:03:00-04:00</updated>
    <id>http://DRSNJM.github.com/blog/2012/10/30/designing-the-scoring-engine</id>
    <content type="html"><![CDATA[<p>In <a href="http://DRSNJM.github.com/blog/2012/09/17/preferences-and-constraints/">a previous post</a>, I
discussed the differences between filtering on constraints and scoring on
preferences. As of the last timebox, filtering on game length was implemented
(that is, using the interface, a user could return games of only certain
lengths). For this timebox, I completed the filtering step on the only other
constraint that needs to be filtered on, the number of players.</p>

<p>That is the easy part. Scoring games can get very tricky. At the highest
level, it&#8217;s very intuitive; you simply compare the user preferences to the
game attributes and sum up scores for each match. The most pertinent question
is, what will the numerical score values be based on? Will they be
normalized? To answer the question of normalization, there is no need to
normalize the scores for each match. The only place the scores will be used
is in the ordering of the games presented to the user. In other words, the
scores only need be relative.</p>

<p>What defines a match? If we only considered matches as the user&#8217;s preference
being exactly the same as the game&#8217;s attribute, and all else won&#8217;t earn you
any score, then our job as programmers would be fairly easy. However, the
fact of that matter is that many games may have <em>partial</em> matches; they match
to some degree. For example, if a user indicates that they prefer a light
game, we may want to give some &#8220;full&#8221; score to all light games, but maybe 75%
of the points if the game is medium light, 45% if medium, and 10% if medium
heavy. Unforunately, this implies that the scoring functions need to be
written for each attribute individually, as the degree to which an attribute
matches a preference is dependant upon the attribute.</p>

<p>The final question is, where do we get the scores? This brings us back to the
original goal of this project: to emulate an expert in the field of board
game recommendations. We don&#8217;t need to come up with the scores ourselves; we
need to get experts to tell use what the scores on the attributes ought to be.
 In the future, this will be important information to extract from our experts.</p>

<p>The last thing to consider is that we will be adding explanations on scores
for display on the results page. This means that as each match is made, a
corresponding string must be written or generated that describes what was
matched and how much it affected the score. We can simply maintain a running
list of explanations alongside the score to pass back from the game engine.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interview 4: Corey Sanders]]></title>
    <link href="http://DRSNJM.github.com/blog/2012/10/19/interview-4-corey-sanders/"/>
    <updated>2012-10-19T19:39:00-04:00</updated>
    <id>http://DRSNJM.github.com/blog/2012/10/19/interview-4-corey-sanders</id>
    <content type="html"><![CDATA[<p>For more <a href="http://DRSNJM.github.com/experts#corey">information about Corey Sanders</a> see the experts page.</p>

<p>A recording of the interview is accessible
<a href="http://dl.dropbox.com/u/1378350/cse5914/corey-1.3gp">here</a>.</p>

<h2>Notes</h2>

<p>For the most part, Corey reiterated a lot of the things we have heard from
interviews with other experts.  The attributes he suggested are:</p>

<ul>
<li>Mechanics</li>
<li>Easy to Learn?</li>
<li>Gateway Game?</li>
<li>Rank (from BGG)</li>
<li>Play time</li>
<li>Age Group</li>
<li>Availability &#8211; How easy is it to buy this game in a store?</li>
</ul>


<p>Corey agreed that player skill might also be important and thought that using
most difficult game played might work as well as the number of unique games
played.</p>

<hr />

<h4>Location</h4>

<p>Panera Bread<br />
3625 Fishinger Boulevard<br />
Hilliard, Ohio 43026</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interview 3: Jeff Kayati]]></title>
    <link href="http://DRSNJM.github.com/blog/2012/10/19/interview-3-jeff-kayati/"/>
    <updated>2012-10-19T19:38:00-04:00</updated>
    <id>http://DRSNJM.github.com/blog/2012/10/19/interview-3-jeff-kayati</id>
    <content type="html"><![CDATA[<p>For more <a href="http://DRSNJM.github.com/experts#jeffk">information about Jeff Kayati</a> see the experts page.</p>

<p>A recording of the interview is accessible
<a href="http://dl.dropbox.com/u/1378350/cse5914/jeffk-1.3gp">here</a>.</p>

<h2>Notes</h2>

<p>Beyond reiterating significant attributes we&#8217;ve heard from previous experts Jeff
also suggested that the user be able to specify whether or not they want to
learn a new game or not. Although we are not tracking user plays we could return
more varied results in this case.</p>

<p>Jeff also suggested that we allow the user to access the similarity engine
directly.  That is, a user can query for a game with specific attributes or he
or she can enter another game they like and get a recommendation from that.</p>

<p>Since the published playtime of a game is often far shorter than actual plays to
new board game players Jeff suggested adjusting playtime based on player skill
level.</p>

<p>Similar to Jeff Horger&#8217;s suggestion that we filter by publisher, Kayati also
suggested we allow filtering on designer. Also like Jeff Horger, Kayati though
allowing the user to exclude certain attributes is very important.</p>

<hr />

<h4>Location</h4>

<p>The Soldiery, Inc.<br />
4256 N. High St<br />
Columbus, Ohio 43214</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Similarity Engine Design and Machine Learning Tools]]></title>
    <link href="http://DRSNJM.github.com/blog/2012/10/19/similarity-engine-design-and-machine-learning-tools/"/>
    <updated>2012-10-19T14:50:00-04:00</updated>
    <id>http://DRSNJM.github.com/blog/2012/10/19/similarity-engine-design-and-machine-learning-tools</id>
    <content type="html"><![CDATA[<p>My reponsibilities for Timebox #3 have primarily revolved around the machine learning extension to our project. After the expert interviews and discussion with potential users that took place during this timebox, it was decided that a search that provides recommended games based on some individual game that a user had enjoyed playing would be very useful and should be surfaced as a main feaure of the application, giving greater weight to this portion of the project. Elaborating on my <a href="http://DRSNJM.github.com/blog/2012/09/21/similarity-engine/">previous post on the topic</a>, I will be discussing some of the design and implementation decisions we have made.</p>

<h2>Creating a Training Set</h2>

<p>One of the challenges of developing a machine learning system, in our case, is having a reliable and sufficiently large training set to use to train the machine implementations we decide to use. This responsibility will fall on our experts and other experienced members of CABS. The number of games in our current input space is currently at 1000, and may be expanded in the future. Since his experts have to be able to rate games in terms of each other, we decided that an interface that randomly selects a set of ~16 games, and then asks which of those games the user is familiar with, would result in much more efficient training. These selections would then be passed to the game comparison screen, described previously, in which the users selects on a sliding scale how much they would recommend the second game based on someone enjoying the first.</p>

<p>Some of the issues that arise from this system include the potential for multiple experts to rate the same pair of games. It is because of this, and also the fact that we dont want experts to be presented the same game pair more than once, that it is necessary to keep track of which training patterns belong to which expert. When it comes time to actually train the system, any duplicates will be averaged together to create the final training set.</p>

<h2>Input Data</h2>

<p>Another step in implementing the system is to produce a set of input data that can be fed through the network. Currently, a record for a single game in the database looks like the following:</p>

<pre><code>{
  "_id" : ObjectId("507ddc8538ef1f102b000001"),
  "bgg_id" : 12002,
  "name" : "Jambo",
  "thumbnail" : "http://cf.geekdo-images.com/images/pic1244694_t.jpg",
  "image" : "http://cf.geekdo-images.com/images/pic1244694.jpg",
  "min_players" : 2,
  "max_players" : 2,
  "min_age" : 12,
  "length" : 45,
  "year_published" : 2004,
  "rating_average" : 7.13898,
  "rating_bayes_average" : 7.01279,
  "rating_std_dev" : 1.19381,
  "rating_median" : 0,
  "weight_average" : 2.0779,
  "weight_num" : 693,
  "rank" : 233,
  "tags" : [
    {
      "bgg_id" : 1002,
      "subtype" : "category",
      "value" : "Card Game"
    }

    ...

  },
  "suggested_age" : {
    "2" : 0,
    "3" : 0,
    "4" : 0,
    "5" : 0,
    "6" : 1,
    "8" : 2,
    "10" : 14,
    "12" : 8,
    "14" : 2,
    "16" : 0,
    "18" : 0,
    "21 and up" : 0
  }
}
</code></pre>

<p>However, in order to appropriate input for a machine learning implementation, the input must be a vector of numerical values, so I have begun to write a map function to perform this conversion, which can be seen <a href="https://github.com/DRSNJM/board-ultimatum/blob/nnet/src/board_ultimatum/engine/vector-convert.clj">here</a>. The output for the game then looks like the following:</p>

<pre><code>[0.0075 0.25 0.25 0.6666666666666666 0.233 0.3465]
</code></pre>

<p>One interesting issue with our set of data is the possibility of having a very large input vector. Ryan and I have discussed this issue and have been researching techniques such as <a href="http://en.wikipedia.org/wiki/Principal_component_analysis">principal component analysis</a>, among others, as a possible solution to reduce the number of dimensions of our input. The primary concern is training performance, however, I have not yet had the chance to do any sort of dummy training to get an idea of what the limitations are going to be.</p>

<h2>Machine Learning</h2>

<p>Initially we had discussed using <a href="http://www.cs.waikato.ac.nz/ml/weka/">Weka</a> as our machine learning library, however, after looking into the documentation, it seemed that the neural nets and other features were primarily geared towards being used as classifiers. The domain for our problem falls more into function approximation, as we want to be able to return and train with values in a continuous range, rather than a discrete one.</p>

<p>After looking at my options, I decided to go with <a href="http://www.heatonresearch.com/encog">Encog</a>. Encog has a repuation for being mature and rather optimized in terms of performance. It also has a well-documented Clojure wrapper, <a href="https://github.com/jimpil/enclog">Enclog</a>. Encog offers a variety of network types as well as training algorithms that I will need to experiment with to determine what approach is most appropriate for our input data.</p>

<h2>Returning the Results</h2>

<p>In order to quickly return the values generated by the network, we went ahead and set up a <a href="http://redis.io/">Redis</a> instance that is hooked to our Heroku account. We will be using the <a href="http://redis.io/commands#sorted_set">sorted sets</a> data structure to hold the results. The sorted set in redis takes input in the following format:</p>

<pre><code>key score member
</code></pre>

<p>In our situation, the data we will be inputting will look like the following:</p>

<pre><code>GameID-A similiarty-value GameID-B
</code></pre>

<p>This way, we will be able to very efficiently query what games, given some game A, have a similarity-value in a certain range. The <a href="http://redis.io/commands/zrevrange">zrevrange function</a> will most likely be the most appropriate for making these queries. Once the Game ID&#8217;s have been retrieved, the normal game database can then be queried to provide full details on each game.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Timebox 3]]></title>
    <link href="http://DRSNJM.github.com/blog/2012/10/18/timebox-3/"/>
    <updated>2012-10-18T23:16:00-04:00</updated>
    <id>http://DRSNJM.github.com/blog/2012/10/18/timebox-3</id>
    <content type="html"><![CDATA[<p>For detailed information on accomplishments from this timebox, see the links
below:</p>

<ul>
<li><a href="http://DRSNJM.github.com/blog/2012/10/18/interface-design/">Attribute search design</a></li>
<li><a href="http://DRSNJM.github.com/blog/2012/10/16/interface-implementation/">Attribute search implementation</a></li>
</ul>


<h4>Interviews</h4>

<ol>
<li><a href="http://DRSNJM.github.com/blog/2012/10/19/interview-2-jeff-1/">Jeff Horger</a></li>
<li><a href="http://DRSNJM.github.com/blog/2012/10/19/interview-3-jeff-kayati/">Jeff Kayati</a></li>
<li><a href="http://DRSNJM.github.com/blog/2012/10/19/interview-4-corey-sanders/">Corey Sanders</a></li>
</ol>


<h2>Worklog</h2>

<h3>Chris Powers</h3>

<ul>
<li>Front-end mockups</li>
<li>Tri-State button functionality</li>
</ul>


<h3>Alex Burkhart</h3>

<ul>
<li>Load mongodb from BGG data</li>
<li>Get simple query functionality working</li>
<li>Make prototype query results page.</li>
</ul>


<h3>Ryan McGowan</h3>

<p>Ryan primarily managed code being included into our master branch.  He did most
of the merging of features and refactored several components.</p>

<ul>
<li>Create initial project scaffolding.

<ul>
<li>Bootstrap, Leiningen, Mongo and the wiring between them to have a
running app. This includes the config functionality.</li>
</ul>
</li>
<li>Refactor Javascript for query interface.</li>
<li>Corrections to markup for query interface to properly use bootstrap
scaffolding.</li>
<li>Feature branch merges</li>
<li>Refactor <code>expert.js</code> and the expert select interface to use bootstrap
scaffolding.</li>
<li>Several other style changes.</li>
<li>Interview writeups and notes</li>
</ul>


<h3>David Albert</h3>

<ul>
<li>Initial bootstrap UI demo</li>
<li>Machine Learning component R&amp;D
(<a href="http://DRSNJM.github.com/blog/2012/10/19/similarity-engine-design-and-machine-learning-tools/">more details here</a>)</li>
</ul>


<h2>Commit History</h2>

<p>For more information on who has done what see <a href="https://github.com/DRSNJM/board-ultimatum/commits/master">our commit
history</a> on our github
project.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Group Presentation on Timebox 3 Updates]]></title>
    <link href="http://DRSNJM.github.com/blog/2012/10/16/group-presentation-timebox-3/"/>
    <updated>2012-10-16T23:03:00-04:00</updated>
    <id>http://DRSNJM.github.com/blog/2012/10/16/group-presentation-timebox-3</id>
    <content type="html"><![CDATA[<p>Our group gave a presentation today on our project updates for timebox 3.
The presentation slides are <a href="https://docs.google.com/presentation/d/1FlgUpLTmazz8MjVawLmZQl6e1MjkDUkvp96wcXEjtxE/edit">available here</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Attribute Search Interface Implementation]]></title>
    <link href="http://DRSNJM.github.com/blog/2012/10/16/interface-implementation/"/>
    <updated>2012-10-16T13:35:00-04:00</updated>
    <id>http://DRSNJM.github.com/blog/2012/10/16/interface-implementation</id>
    <content type="html"><![CDATA[<p>The most fundamental aspects of the query interface have been implemented.
Though there may be more attributes added in the future, we decided to add a
select few attributes that we believed encapsulated differing types of input we
receive from the user. In particular, we expect the user to select discrete
values for some attributes, such as number of players and time to play (in
discrete intervals), and tri-state objects that can encapsulate the user liking,
disliking, or not caring about a particular attribute. Prototypes were built to
represent these input types, and are currently present on the interface:</p>

<p><img src="http://DRSNJM.github.com/images/diagrams/fundamental-interface.jpeg" alt="Fundamental interface" /></p>

<p>These input types maintain hidden values in the background in order to formally
send them to the server.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interview 2: Jeff Horger]]></title>
    <link href="http://DRSNJM.github.com/blog/2012/10/08/interview-2-jeff-1/"/>
    <updated>2012-10-08T20:00:00-04:00</updated>
    <id>http://DRSNJM.github.com/blog/2012/10/08/interview-2-jeff-1</id>
    <content type="html"><![CDATA[<p>For more <a href="http://DRSNJM.github.com/experts#jeffh">information about Jeff Horger</a> see the experts page.</p>

<p>A recording of the interview is accessible
<a href="http://dl.dropbox.com/u/1378350/cse5914/jeffh-1.3gp">here</a>.</p>

<h2>Notes</h2>

<p>As with most of our experts we asked Jeff a few basic questions:</p>

<ol>
<li>How do you pick what game to play?</li>
<li>How do you determine what game to suggest to another player?</li>
<li>What attributes do you think are important to consider when selecting a game
to play?</li>
</ol>


<h4>1.  Choosing for Self</h4>

<p>Jeff selects games to play far in advance and has a rotation set up with fellow
players. Thus he always knows what he is going to play.  Foremost Jeff considers
those he is playing with when selecting games in this fashion.</p>

<p>Here are some attributes Jeff specifically mention he though of:</p>

<ul>
<li>Mental or Fun? &#8211; Does the game require a lot of thinking or is it simpler
than that.</li>
<li>Hard or Easy (i.e. weight)</li>
<li>Complexity</li>
</ul>


<h4>2.  Suggesting to Others</h4>

<p>Jeff always asks leading questions before making a suggestion. He takes into
account the likes and dislikes of the other player.  He plays special attention
to theme.  He also strongly regrades exclusions made by other players.  If some
one hates games published by Fantasy Flight, then Jeff certainly will not
suggest one that was.</p>

<p>Jeff also suggested that we put default to placing simpler games before more
complex ones since that&#8217;s what most new players would prefer.</p>

<h4>3.  Attributes</h4>

<p>(Besides those listed in 1)</p>

<ul>
<li>Play time</li>
<li>Gauge skill by the hardest game the client has ever played.</li>
<li>Difficulty to learn will correlate highly with number of metrics.</li>
<li>Publishers typically produce games for audience at a certain skill level so
they can be mapped to difficulty to learn.</li>
</ul>


<hr />

<h4>Location</h4>

<p>The Soldiery, Inc.<br />
4256 N. High St<br />
Columbus, Ohio 43214</p>
]]></content>
  </entry>
  
</feed>
